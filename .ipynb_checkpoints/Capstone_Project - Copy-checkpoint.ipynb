{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranking Prediction of Higher Education Institutes using Financial and Expenditure Data \n",
    "\n",
    "## Supervised Machine Learning\n",
    "\n",
    "### by Mohamad Zeini Jahromi\n",
    "Sep 18th, 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Overview\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total number of awards, certificates, and degrees completed each year in post-secondary education institutions have been widely used to evaluate their performances and are an indication of relative success and ranking of these institutions throughout the nation. Many studies have investigated the effects of different parameters (such as financial aid, institutes funds, revenue, expenditures and etc.) on the institutes completion rates. The results of these studies could help institutions to decide how to allocate funds to their segments more effectively and create a well-balanced money flow within their systems. On the other hand, the costs of higher education in the United Sates are high and it’s being considered as an investment and consequently having a knowledge of success rate and ranking of a specific institution would help both students and their families in making the right decision.\n",
    "\n",
    "This project focuses on studying the relationship between institutions financial aid and expenditure and their respective completion rates (the total number of award, certificate, and degree completed). Furthermore, a predictive model will be developed in order to predict the completion rates using the financial aid and expenditure data of institutions.\n",
    "This study is inspired by Udacity's capstone project guidelines and uses the IPEDS dataset ([Integrated Postsecondary Education Data System Delta Cost Project Database](https://nces.ed.gov/ipeds/deltacostproject/)), which is based on surveys on finance, enrollment, staffing, completions, and student aid of post-secondary education institutions within the US. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "As stated above, the completion rates (the total number of award, certificate, and degree completed) is a measure of success and ranking of institutions. This study is seeking to find out whether the completion rates could be predicted based on financial aid and expenditure data from post-secondary education institutions and in the following, the results will be analyzed to see which parameters are more significant in terms of predicting the target label (completion rates).  \n",
    "\n",
    "## Solution Strategy\n",
    "Different algorithms (**K-Nearest Neighbor Regressors, Support Vector Regressors, Random Forest Regressors** and etc.) will be used to create predictive models. Eventually, these models will be able to predict a specific institution completion rate based on its expenditure or financial aid features. \n",
    "\n",
    "The data cleaning process will be performed on the dataset to eliminate outliers or missing values and then cross-validation is used to split the dataset into a training and a testing datasets. \n",
    "\n",
    "The Principal Component Analysis will be implemented to find the dimensions that explain the most of the variance. The top components become predicting features for creating the model. Before the PCA procedure, the standardizing and transforming procedures will be performed on the dataset. The models will be tuned using Grid Search function using sets of hyperparameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics\n",
    "It is difficult to measure the quality of a given model without quantifying its performance over training and testing. This is typically done using some type of performance metric, whether it is through calculating some type of error, the goodness of fit, or some other useful measurement. For this project, we will be calculating the [*coefficient of determination*](http://stattrek.com/statistics/dictionary.aspx?definition=coefficient_of_determination) (R<sup>2</sup>) to quantify our model's performance. The coefficient of determination for a model is a useful statistic in regression analysis, as it often describes how \"good\" that model is at making predictions.\n",
    "\n",
    "The values for R<sup>2</sup> range from 0 to 1, which captures the percentage of squared correlation between the predicted and actual values of the **target variable**. A model with an R<sup>2</sup> of 0 is no better than a model that always predicts the mean of the target variable, whereas a model with an R<sup>2</sup> of 1 perfectly predicts the target variable. Any value between 0 and 1 indicates what percentage of the target variable, using this model, can be explained by the **features**. R<sup>2</sup>, however, inflates when adding more predictors (variables) to the metric. The variance caused by predicted value hence increase even without model improvement. Adjusted R<sup>2</sup> score is developed to counter the inflation and adding a penalty for additional variables entering the metric. Adjusted R<sup>2</sup> is always smaller or equal to R<sup>2</sup> score. A model can be given a negative R<sup>2</sup> as well, which indicates that the model is arbitrarily worse than one that always predicts the mean of the target variable.\n",
    "\n",
    "For the `performance_metric` function in the code cell below, we implement the following:\n",
    "- Use `r2_score` from `sklearn.metrics` to perform a performance calculation between `y_true` and `y_predict`.\n",
    "- Assign the performance score to the `score` variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import 'r2_score'\n",
    "from sklearn.metrics import r2_score \n",
    "\n",
    "def performance_metric(y_true, y_predict):\n",
    "    \"\"\" Calculates and returns the performance score between \n",
    "        true and predicted values based on the metric chosen. \"\"\"\n",
    "    \n",
    "    # Calculate the performance score between 'y_true' and 'y_predict'\n",
    "    score = r2_score(y_true, y_predict)\n",
    "    # Return the score\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "The dataset used in this project are from IPDES database ([Integrated Postsecondary Education Data System Delta Cost Project Database](https://nces.ed.gov/ipeds/deltacostproject/)), which is based on surveys on finance, enrollment, staffing, completions, and student aid of post-secondary education institutions in the US. It consists of many features including financial aid, revenue, and expenditure of institutes across the US. The datasets for academic years of 1987-1999 and 2000-2012 have the total number 215613 entries and 974 features. All expenditure categories (20 features) are used as the **Expenditure Features** and in the same way, the financial aid categories (5 features) are used as the **Financial aid Features**. Also, the categories that contain total completions value are going through further preprocessing to create the **Completion Rates Label**.\n",
    "\n",
    "The selected features are numerical, and since the dataset contains a significant amount of null value (missing data or unreported data), multiple data cleaning scenarios will be performed which results in eliminating some features and data points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mo\\Anaconda3\\envs\\DAND\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2717: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPEDS datasets has 215613 data points with 974 variables each.\n"
     ]
    }
   ],
   "source": [
    "# Import libraries necessary for this project\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# Import supplementary visualizations code visuals.py\n",
    "import visuals as vs\n",
    "\n",
    "# Pretty display for notebooks\n",
    "%matplotlib inline\n",
    "\n",
    "#load IPEDS datasets\n",
    "data_00_12=pd.read_csv(\"delta_public_00_12.csv\")\n",
    "data_87_99=pd.read_csv(\"delta_public_87_99.csv\")\n",
    "\n",
    "#concatenate datasets\n",
    "data=pd.concat([data_00_12,data_87_99])\n",
    "\n",
    "# Success\n",
    "print \"IPEDS datasets has {} data points with {} variables each.\".format(*data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>groupid</th>\n",
       "      <th>academicyear</th>\n",
       "      <th>unitid_linchpin</th>\n",
       "      <th>unitid</th>\n",
       "      <th>isgrouped</th>\n",
       "      <th>ansi_code</th>\n",
       "      <th>sector</th>\n",
       "      <th>sector_revised</th>\n",
       "      <th>iclevel</th>\n",
       "      <th>control</th>\n",
       "      <th>...</th>\n",
       "      <th>Iptall1</th>\n",
       "      <th>Iptall2</th>\n",
       "      <th>Iptall3</th>\n",
       "      <th>Iptall4</th>\n",
       "      <th>Iptall5</th>\n",
       "      <th>Iptall6</th>\n",
       "      <th>Iptall7</th>\n",
       "      <th>Iptall8</th>\n",
       "      <th>Ifaculty_instr_headcount</th>\n",
       "      <th>Isalarytotal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>215613.000000</td>\n",
       "      <td>215613.000000</td>\n",
       "      <td>215613.000000</td>\n",
       "      <td>215613.000000</td>\n",
       "      <td>215613.000000</td>\n",
       "      <td>215613.00000</td>\n",
       "      <td>215613.00000</td>\n",
       "      <td>215613.000000</td>\n",
       "      <td>215613.000000</td>\n",
       "      <td>215613.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>215613.000000</td>\n",
       "      <td>215613.000000</td>\n",
       "      <td>215613.000000</td>\n",
       "      <td>215613.000000</td>\n",
       "      <td>215613.000000</td>\n",
       "      <td>215613.000000</td>\n",
       "      <td>215613.000000</td>\n",
       "      <td>215613.000000</td>\n",
       "      <td>215613.000000</td>\n",
       "      <td>215613.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-206710.434320</td>\n",
       "      <td>1997.929411</td>\n",
       "      <td>222154.658193</td>\n",
       "      <td>222154.658193</td>\n",
       "      <td>0.074597</td>\n",
       "      <td>28.13802</td>\n",
       "      <td>5.65753</td>\n",
       "      <td>5.664890</td>\n",
       "      <td>2.041561</td>\n",
       "      <td>2.243116</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.453512</td>\n",
       "      <td>-1.599328</td>\n",
       "      <td>-1.575053</td>\n",
       "      <td>-1.506635</td>\n",
       "      <td>-1.555509</td>\n",
       "      <td>-1.487647</td>\n",
       "      <td>-1.609745</td>\n",
       "      <td>-1.532125</td>\n",
       "      <td>-0.749055</td>\n",
       "      <td>-0.748104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>113440.202448</td>\n",
       "      <td>7.448015</td>\n",
       "      <td>99592.246073</td>\n",
       "      <td>99592.246073</td>\n",
       "      <td>0.262740</td>\n",
       "      <td>16.53170</td>\n",
       "      <td>5.33754</td>\n",
       "      <td>5.333179</td>\n",
       "      <td>0.927678</td>\n",
       "      <td>0.844804</td>\n",
       "      <td>...</td>\n",
       "      <td>0.891252</td>\n",
       "      <td>0.800505</td>\n",
       "      <td>0.818118</td>\n",
       "      <td>0.862163</td>\n",
       "      <td>0.831512</td>\n",
       "      <td>0.873043</td>\n",
       "      <td>0.792599</td>\n",
       "      <td>0.846668</td>\n",
       "      <td>0.605949</td>\n",
       "      <td>0.608012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-475291.000000</td>\n",
       "      <td>1987.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-236072.000000</td>\n",
       "      <td>1991.000000</td>\n",
       "      <td>151360.000000</td>\n",
       "      <td>151360.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.00000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-189918.000000</td>\n",
       "      <td>1997.000000</td>\n",
       "      <td>196334.000000</td>\n",
       "      <td>196334.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.00000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-140386.000000</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>238661.000000</td>\n",
       "      <td>238661.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41.00000</td>\n",
       "      <td>9.00000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3041.000000</td>\n",
       "      <td>2012.000000</td>\n",
       "      <td>475291.000000</td>\n",
       "      <td>475291.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>78.00000</td>\n",
       "      <td>99.00000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 969 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             groupid   academicyear  unitid_linchpin         unitid  \\\n",
       "count  215613.000000  215613.000000    215613.000000  215613.000000   \n",
       "mean  -206710.434320    1997.929411    222154.658193  222154.658193   \n",
       "std    113440.202448       7.448015     99592.246073   99592.246073   \n",
       "min   -475291.000000    1987.000000      1025.000000    1025.000000   \n",
       "25%   -236072.000000    1991.000000    151360.000000  151360.000000   \n",
       "50%   -189918.000000    1997.000000    196334.000000  196334.000000   \n",
       "75%   -140386.000000    2004.000000    238661.000000  238661.000000   \n",
       "max      3041.000000    2012.000000    475291.000000  475291.000000   \n",
       "\n",
       "           isgrouped     ansi_code        sector  sector_revised  \\\n",
       "count  215613.000000  215613.00000  215613.00000   215613.000000   \n",
       "mean        0.074597      28.13802       5.65753        5.664890   \n",
       "std         0.262740      16.53170       5.33754        5.333179   \n",
       "min         0.000000       1.00000       0.00000        0.000000   \n",
       "25%         0.000000      13.00000       2.00000        2.000000   \n",
       "50%         0.000000      27.00000       6.00000        6.000000   \n",
       "75%         0.000000      41.00000       9.00000        9.000000   \n",
       "max         1.000000      78.00000      99.00000       99.000000   \n",
       "\n",
       "             iclevel        control      ...              Iptall1  \\\n",
       "count  215613.000000  215613.000000      ...        215613.000000   \n",
       "mean        2.041561       2.243116      ...            -1.453512   \n",
       "std         0.927678       0.844804      ...             0.891252   \n",
       "min        -3.000000      -3.000000      ...            -2.000000   \n",
       "25%         1.000000       2.000000      ...            -2.000000   \n",
       "50%         2.000000       2.000000      ...            -2.000000   \n",
       "75%         3.000000       3.000000      ...             0.000000   \n",
       "max         3.000000       3.000000      ...             0.000000   \n",
       "\n",
       "             Iptall2        Iptall3        Iptall4        Iptall5  \\\n",
       "count  215613.000000  215613.000000  215613.000000  215613.000000   \n",
       "mean       -1.599328      -1.575053      -1.506635      -1.555509   \n",
       "std         0.800505       0.818118       0.862163       0.831512   \n",
       "min        -2.000000      -2.000000      -2.000000      -2.000000   \n",
       "25%        -2.000000      -2.000000      -2.000000      -2.000000   \n",
       "50%        -2.000000      -2.000000      -2.000000      -2.000000   \n",
       "75%        -2.000000      -2.000000      -2.000000      -2.000000   \n",
       "max         0.000000       0.000000       0.000000       0.000000   \n",
       "\n",
       "             Iptall6        Iptall7        Iptall8  Ifaculty_instr_headcount  \\\n",
       "count  215613.000000  215613.000000  215613.000000             215613.000000   \n",
       "mean       -1.487647      -1.609745      -1.532125                 -0.749055   \n",
       "std         0.873043       0.792599       0.846668                  0.605949   \n",
       "min        -2.000000      -2.000000      -2.000000                 -2.000000   \n",
       "25%        -2.000000      -2.000000      -2.000000                 -1.000000   \n",
       "50%        -2.000000      -2.000000      -2.000000                 -1.000000   \n",
       "75%         0.000000      -2.000000      -2.000000                  0.000000   \n",
       "max         0.000000       0.000000       0.000000                  1.000000   \n",
       "\n",
       "        Isalarytotal  \n",
       "count  215613.000000  \n",
       "mean       -0.748104  \n",
       "std         0.608012  \n",
       "min        -2.000000  \n",
       "25%        -1.000000  \n",
       "50%        -1.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 969 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Observation\n",
    "The following, shows the data subset features that are being selected to be used in this project. The table has 27 rows including 20 Expenditure features, 5 Financial aid features, the **totalcompletions** target label and the **has_completion** tag. A brief explanation of each feature is provided in the next column.\n",
    "\n",
    "**Eligible data points:**\n",
    "* **has_completion**: Indicator of whether totalcompletions is reported. (0=not reported; 1=reported)\n",
    "\n",
    "**Label:**\n",
    "* **totalcompletions**: the total number of degree, award, certificate granted of the current year. \n",
    "\n",
    "**Features (Expenditure):**\n",
    "* **instruction01**: instructional expenses for the institution and excludes administration, operations and maintenance.\n",
    "* **research01**: expense used to produce research outcomes excluding operation and maintenance, interest amounts attributed to the research functions.\n",
    "* **pubserv01**: expense category that provides noninstructional services beneficial to individuals and groups external to the institution such as conferences. Operations and maintenance, interest amounts attributed to the research function are excluded.\n",
    "* **acadsupp01**: expenses to support instruction, research, and public service. This category includes retention, preservation, and display of education materials. Operations and maintenance and interest amounts attributed to the academic support function are excluded.\n",
    "* **studserv01**: expenses associate with admissions, registrar activities, and activities that contribute to students' emotional and physical well-being and their intellectual, cultural, and social development outside the formal instructional program. Operations and maintenance (and interest in the 2009 aligned form) amounts attributed to the student services function are excluded.\n",
    "* **instsupp01**: expense for day-to-day operational support of the institution such as space management, employee personnel, and records. Operations and maintenance and interest amounts attributed to the institutional support are excluded.\n",
    "* **acadinststud01**: academic and institutional support and student service total of current year\n",
    "* **opermain01**: expenses for operations providing service and maintenance related to campus grounds and facilities. Institutions may optionally distribute depreciation expense to this function.\n",
    "* **depreciation01**: total depreciation of current year\n",
    "* **grants01**: the sum of all operating expenses associated with scholarships and fellowships including payment in support of the cost of education or third parties for off-campus housing. Operations and maintenance and interest amounts are excluded.\n",
    "* **auxiliary01**: expense of all operating associated with essentially self-supporting operations of the institution such as student health services. The amount of interest is excluded.\n",
    "* **hospital01**: operating expenses related to a hospital run by the postsecondary institute.\n",
    "* **independ01**: expenses associated with operations that are independent of or unrelated to the primary missions of the institution. The amount of interest attributed to the independent operations function is excluded as well as for the expenses of operations owned and managed as investments of the institution's endowment funds.\n",
    "\n",
    "* **totaloper01**: total expenses is the sum of all operating expenses that result from providing goods and services. \n",
    "\n",
    "* **otheroper01**: All expense other than categories above which discontinued after the Academy year 2010.\n",
    "* **othernon01**: All other non-operating expense of current year\n",
    "* **other01**: All other expense\n",
    "\n",
    "* **eandg01**: Total education and general expenditures includes all core operating expenditures, including sponsored research, but excluding auxiliary enterprises. \n",
    "\n",
    "\n",
    "* **rschpub01**: expense for research and public service of current year\n",
    "\n",
    "* **acadinststud01**: Expenditures for academic and institutional support and student services.\n",
    "\n",
    "**Features (Financial aid):**\n",
    "\n",
    "* **appliedaid01**: Discounts and allowances applied to tuition and fees are reductions to the amount charged for tuition and fees by the application of scholarships and fellowships. \n",
    "\n",
    "* **grant07**: The sum of Pell, Federal, State, Local, and Institutional Grants (funded and unfunded). \n",
    "\n",
    "* **tuition_discount**: That part of a scholarship or fellowship that is used to pay institutional charges such as tuition and fees or room and board charges.\n",
    "\n",
    "* **any_aid_num**: Number of full-time, first-time degree/certificate-seeking undergraduate students who received any financial aid including grants, loans, assistantships, scholarships, fellowships, tuition waivers, tuition discounts, veteran's benefits, employer aid (tuition reimbursement) and other monies (other than from relatives/friends) provided to students to meet expenses. \n",
    "\n",
    "* **loan_num**: Number of full-time, first-time degree/certificate-seeking undergraduate students who received student loans. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label = ['totalcompletions']\n",
    "\n",
    "expenditure = ['instruction01','research01','pubserv01','acadsupp01','studserv01','instsupp01',\n",
    "               'opermain01','depreciation01','grants01','auxiliary01','hospital01','independ01',\n",
    "               'totaloper01','otheroper01','othernon01','other01','eandg01','rschpub01',\n",
    "               'acadinststud01']\n",
    "           \n",
    "financial_aid = ['appliedaid01', 'grant07','tuition_discount','any_aid_num','loan_num']\n",
    "\n",
    "eligibility = ['has_completions'] \n",
    "\n",
    "data = data[eligibility + label + expenditure + financial_aid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of institutions eligible with completion data: 142220\n",
      "Number of data point with Negative value: 166367\n",
      "Number of data point with Null value: 3766731 \n",
      "\n",
      "Number of data point with Null value for each feature:\n",
      "has_completions          0\n",
      "totalcompletions     72733\n",
      "instruction01        99565\n",
      "research01          189057\n",
      "pubserv01           174161\n",
      "acadsupp01          133299\n",
      "studserv01          108102\n",
      "instsupp01          130750\n",
      "opermain01          136464\n",
      "depreciation01      174980\n",
      "grants01            152047\n",
      "auxiliary01         141043\n",
      "hospital01          213328\n",
      "independ01          212062\n",
      "totaloper01         163432\n",
      "otheroper01         210332\n",
      "othernon01          210227\n",
      "other01             180551\n",
      "eandg01              98740\n",
      "rschpub01           166136\n",
      "acadinststud01      103254\n",
      "appliedaid01        165228\n",
      "grant07             102923\n",
      "tuition_discount    134480\n",
      "any_aid_num         146899\n",
      "loan_num            146938\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print 'Number of institutions eligible with completion data:',(data['has_completions'] == 1).sum()\n",
    "print 'Number of data point with Negative value:', (data < 1).sum().sum()\n",
    "print 'Number of data point with Null value:', data.isnull().sum().sum(), '\\n'\n",
    "print 'Number of data point with Null value for each feature:\\n', data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "Before data can be used as input for machine learning algorithms, it often must be cleaned, formatted, and restructured (preprocessing). Some initial observations are as follows:\n",
    "* The **has_completion** feature shows that only 142220 out of total number of 215613 entries are eligible institutions with the completion rates data.\n",
    "* 166367 of data points have negative values (which does not make sense in terms of dollars)\n",
    "* 3766731 of data points have Null value or missing.\n",
    "\n",
    "In the first step, all the entries without the completion rates data are removed. Next, the features that include more than 80% of Null or missing values are removed. Then, the remaining data points that have Null or missing values, or negative values are eliminated. \n",
    "After initial data cleaning procedure, the dataset is left with 4609 entries and 21 columns (including 19 features, the **totalcompletions** target label, and the **has_completion** tag). This preprocessing significantly improves the accuracy of outcomes and the predictive power of learning algorithms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(142220, 26)  New data structure after removing uneligible values without completion data\n",
      "(142220, 21)  New data structure after removing columns with more than 80% Null\n",
      "(4613, 21)  New data structure after removing Null values\n",
      "(4609, 21)  New data structure after removing Negative values\n"
     ]
    }
   ],
   "source": [
    "#Excluding data point with out report of totalcompletion\n",
    "data = data[data['has_completions'] == 1]\n",
    "print data.shape, ' New data structure after removing uneligible values without completion data'\n",
    "\n",
    "# Remove columns with more than 80% Null data\n",
    "for k in data.keys():\n",
    "    if (data[k].isnull().sum() / float(len(data)))> 0.8:\n",
    "        data.drop(k, axis=1, inplace=True)\n",
    "print data.shape, ' New data structure after removing columns with more than 80% Null'\n",
    "\n",
    "# Drop the data points with Null data\n",
    "data.dropna(inplace=True)\n",
    "print data.shape, ' New data structure after removing Null values'\n",
    "\n",
    "# Drop the negative data points \n",
    "data = (data[data >= 0]).dropna()\n",
    "print data.shape, ' New data structure after removing Negative values'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Statistics\n",
    "The following Table summarizes the descriptive statistics of Expenditure/Financial datasets are calculated. *numpy* library has already been imported and used to perform the necessary calculations. These statistics will be extremely important later on to analyze various prediction results from the constructed model. The minimum, maximum, mean, median, and standard deviation of few features are presented in the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_completions</th>\n",
       "      <th>totalcompletions</th>\n",
       "      <th>instruction01</th>\n",
       "      <th>pubserv01</th>\n",
       "      <th>acadsupp01</th>\n",
       "      <th>studserv01</th>\n",
       "      <th>instsupp01</th>\n",
       "      <th>opermain01</th>\n",
       "      <th>depreciation01</th>\n",
       "      <th>grants01</th>\n",
       "      <th>...</th>\n",
       "      <th>totaloper01</th>\n",
       "      <th>other01</th>\n",
       "      <th>eandg01</th>\n",
       "      <th>rschpub01</th>\n",
       "      <th>acadinststud01</th>\n",
       "      <th>appliedaid01</th>\n",
       "      <th>grant07</th>\n",
       "      <th>tuition_discount</th>\n",
       "      <th>any_aid_num</th>\n",
       "      <th>loan_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4609.0</td>\n",
       "      <td>4609.000000</td>\n",
       "      <td>4.609000e+03</td>\n",
       "      <td>4.609000e+03</td>\n",
       "      <td>4.609000e+03</td>\n",
       "      <td>4.609000e+03</td>\n",
       "      <td>4.609000e+03</td>\n",
       "      <td>4.609000e+03</td>\n",
       "      <td>4.609000e+03</td>\n",
       "      <td>4.609000e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>4.609000e+03</td>\n",
       "      <td>4.609000e+03</td>\n",
       "      <td>4.609000e+03</td>\n",
       "      <td>4.609000e+03</td>\n",
       "      <td>4.609000e+03</td>\n",
       "      <td>4.609000e+03</td>\n",
       "      <td>4.609000e+03</td>\n",
       "      <td>4.609000e+03</td>\n",
       "      <td>4609.000000</td>\n",
       "      <td>4609.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2153.595916</td>\n",
       "      <td>6.676407e+07</td>\n",
       "      <td>1.189261e+07</td>\n",
       "      <td>1.607211e+07</td>\n",
       "      <td>1.026521e+07</td>\n",
       "      <td>1.711139e+07</td>\n",
       "      <td>1.482547e+07</td>\n",
       "      <td>1.347344e+07</td>\n",
       "      <td>9.062319e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>2.271026e+08</td>\n",
       "      <td>6.238758e+06</td>\n",
       "      <td>1.737777e+08</td>\n",
       "      <td>3.969372e+07</td>\n",
       "      <td>4.344387e+07</td>\n",
       "      <td>1.155133e+07</td>\n",
       "      <td>2.202762e+07</td>\n",
       "      <td>1.273067e-01</td>\n",
       "      <td>1098.761987</td>\n",
       "      <td>572.962031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3137.575501</td>\n",
       "      <td>1.392367e+08</td>\n",
       "      <td>3.591096e+07</td>\n",
       "      <td>3.221997e+07</td>\n",
       "      <td>1.592156e+07</td>\n",
       "      <td>3.150710e+07</td>\n",
       "      <td>3.062092e+07</td>\n",
       "      <td>4.290994e+07</td>\n",
       "      <td>1.811422e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>5.170134e+08</td>\n",
       "      <td>4.971934e+07</td>\n",
       "      <td>3.662730e+08</td>\n",
       "      <td>1.189565e+08</td>\n",
       "      <td>7.514446e+07</td>\n",
       "      <td>2.268108e+07</td>\n",
       "      <td>4.018531e+07</td>\n",
       "      <td>1.166008e-01</td>\n",
       "      <td>1508.399685</td>\n",
       "      <td>751.636729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>5.377000e+03</td>\n",
       "      <td>8.300000e+01</td>\n",
       "      <td>1.028000e+03</td>\n",
       "      <td>1.624000e+03</td>\n",
       "      <td>2.144000e+03</td>\n",
       "      <td>1.325000e+03</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>1.510000e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>1.704800e+04</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.565800e+04</td>\n",
       "      <td>8.300000e+01</td>\n",
       "      <td>4.796000e+03</td>\n",
       "      <td>7.800000e+01</td>\n",
       "      <td>3.064000e+03</td>\n",
       "      <td>1.403216e-08</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>529.000000</td>\n",
       "      <td>1.170076e+07</td>\n",
       "      <td>3.964930e+05</td>\n",
       "      <td>2.224223e+06</td>\n",
       "      <td>2.607702e+06</td>\n",
       "      <td>3.736067e+06</td>\n",
       "      <td>2.803707e+06</td>\n",
       "      <td>1.323696e+06</td>\n",
       "      <td>1.697201e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>3.243420e+07</td>\n",
       "      <td>9.183657e+04</td>\n",
       "      <td>2.775764e+07</td>\n",
       "      <td>4.911620e+05</td>\n",
       "      <td>9.047994e+06</td>\n",
       "      <td>1.910207e+06</td>\n",
       "      <td>4.705372e+06</td>\n",
       "      <td>4.620488e-02</td>\n",
       "      <td>301.000000</td>\n",
       "      <td>81.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1100.000000</td>\n",
       "      <td>2.469654e+07</td>\n",
       "      <td>1.610471e+06</td>\n",
       "      <td>5.224699e+06</td>\n",
       "      <td>5.138184e+06</td>\n",
       "      <td>7.529455e+06</td>\n",
       "      <td>6.113570e+06</td>\n",
       "      <td>3.427276e+06</td>\n",
       "      <td>3.824000e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>7.021970e+07</td>\n",
       "      <td>5.576130e+05</td>\n",
       "      <td>5.765063e+07</td>\n",
       "      <td>2.345423e+06</td>\n",
       "      <td>1.818131e+07</td>\n",
       "      <td>4.666428e+06</td>\n",
       "      <td>9.682566e+06</td>\n",
       "      <td>9.833756e-02</td>\n",
       "      <td>638.000000</td>\n",
       "      <td>300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2555.000000</td>\n",
       "      <td>6.110665e+07</td>\n",
       "      <td>5.921572e+06</td>\n",
       "      <td>1.455239e+07</td>\n",
       "      <td>1.195228e+07</td>\n",
       "      <td>1.802700e+07</td>\n",
       "      <td>1.429288e+07</td>\n",
       "      <td>9.279948e+06</td>\n",
       "      <td>9.584321e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>1.685595e+08</td>\n",
       "      <td>2.754737e+06</td>\n",
       "      <td>1.427253e+08</td>\n",
       "      <td>1.292015e+07</td>\n",
       "      <td>4.497659e+07</td>\n",
       "      <td>1.153679e+07</td>\n",
       "      <td>2.239654e+07</td>\n",
       "      <td>1.788751e-01</td>\n",
       "      <td>1345.000000</td>\n",
       "      <td>815.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.0</td>\n",
       "      <td>43561.000000</td>\n",
       "      <td>2.517901e+09</td>\n",
       "      <td>4.051710e+08</td>\n",
       "      <td>4.049135e+08</td>\n",
       "      <td>2.681069e+08</td>\n",
       "      <td>4.765594e+08</td>\n",
       "      <td>6.524091e+08</td>\n",
       "      <td>1.776640e+09</td>\n",
       "      <td>2.914183e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>7.928519e+09</td>\n",
       "      <td>2.408395e+09</td>\n",
       "      <td>6.165973e+09</td>\n",
       "      <td>1.636438e+09</td>\n",
       "      <td>1.067806e+09</td>\n",
       "      <td>3.515930e+08</td>\n",
       "      <td>6.014743e+08</td>\n",
       "      <td>1.774030e+00</td>\n",
       "      <td>23964.000000</td>\n",
       "      <td>9632.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       has_completions  totalcompletions  instruction01     pubserv01  \\\n",
       "count           4609.0       4609.000000   4.609000e+03  4.609000e+03   \n",
       "mean               1.0       2153.595916   6.676407e+07  1.189261e+07   \n",
       "std                0.0       3137.575501   1.392367e+08  3.591096e+07   \n",
       "min                1.0         14.000000   5.377000e+03  8.300000e+01   \n",
       "25%                1.0        529.000000   1.170076e+07  3.964930e+05   \n",
       "50%                1.0       1100.000000   2.469654e+07  1.610471e+06   \n",
       "75%                1.0       2555.000000   6.110665e+07  5.921572e+06   \n",
       "max                1.0      43561.000000   2.517901e+09  4.051710e+08   \n",
       "\n",
       "         acadsupp01    studserv01    instsupp01    opermain01  depreciation01  \\\n",
       "count  4.609000e+03  4.609000e+03  4.609000e+03  4.609000e+03    4.609000e+03   \n",
       "mean   1.607211e+07  1.026521e+07  1.711139e+07  1.482547e+07    1.347344e+07   \n",
       "std    3.221997e+07  1.592156e+07  3.150710e+07  3.062092e+07    4.290994e+07   \n",
       "min    1.028000e+03  1.624000e+03  2.144000e+03  1.325000e+03    5.170000e+02   \n",
       "25%    2.224223e+06  2.607702e+06  3.736067e+06  2.803707e+06    1.323696e+06   \n",
       "50%    5.224699e+06  5.138184e+06  7.529455e+06  6.113570e+06    3.427276e+06   \n",
       "75%    1.455239e+07  1.195228e+07  1.802700e+07  1.429288e+07    9.279948e+06   \n",
       "max    4.049135e+08  2.681069e+08  4.765594e+08  6.524091e+08    1.776640e+09   \n",
       "\n",
       "           grants01     ...        totaloper01       other01       eandg01  \\\n",
       "count  4.609000e+03     ...       4.609000e+03  4.609000e+03  4.609000e+03   \n",
       "mean   9.062319e+06     ...       2.271026e+08  6.238758e+06  1.737777e+08   \n",
       "std    1.811422e+07     ...       5.170134e+08  4.971934e+07  3.662730e+08   \n",
       "min    1.510000e+03     ...       1.704800e+04  1.000000e+00  1.565800e+04   \n",
       "25%    1.697201e+06     ...       3.243420e+07  9.183657e+04  2.775764e+07   \n",
       "50%    3.824000e+06     ...       7.021970e+07  5.576130e+05  5.765063e+07   \n",
       "75%    9.584321e+06     ...       1.685595e+08  2.754737e+06  1.427253e+08   \n",
       "max    2.914183e+08     ...       7.928519e+09  2.408395e+09  6.165973e+09   \n",
       "\n",
       "          rschpub01  acadinststud01  appliedaid01       grant07  \\\n",
       "count  4.609000e+03    4.609000e+03  4.609000e+03  4.609000e+03   \n",
       "mean   3.969372e+07    4.344387e+07  1.155133e+07  2.202762e+07   \n",
       "std    1.189565e+08    7.514446e+07  2.268108e+07  4.018531e+07   \n",
       "min    8.300000e+01    4.796000e+03  7.800000e+01  3.064000e+03   \n",
       "25%    4.911620e+05    9.047994e+06  1.910207e+06  4.705372e+06   \n",
       "50%    2.345423e+06    1.818131e+07  4.666428e+06  9.682566e+06   \n",
       "75%    1.292015e+07    4.497659e+07  1.153679e+07  2.239654e+07   \n",
       "max    1.636438e+09    1.067806e+09  3.515930e+08  6.014743e+08   \n",
       "\n",
       "       tuition_discount   any_aid_num     loan_num  \n",
       "count      4.609000e+03   4609.000000  4609.000000  \n",
       "mean       1.273067e-01   1098.761987   572.962031  \n",
       "std        1.166008e-01   1508.399685   751.636729  \n",
       "min        1.403216e-08      6.000000     0.000000  \n",
       "25%        4.620488e-02    301.000000    81.000000  \n",
       "50%        9.833756e-02    638.000000   300.000000  \n",
       "75%        1.788751e-01   1345.000000   815.000000  \n",
       "max        1.774030e+00  23964.000000  9632.000000  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pandas.tools.plotting import table\n",
    "#Reset dataframe index \n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "display(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction01</th>\n",
       "      <th>pubserv01</th>\n",
       "      <th>acadsupp01</th>\n",
       "      <th>studserv01</th>\n",
       "      <th>instsupp01</th>\n",
       "      <th>opermain01</th>\n",
       "      <th>depreciation01</th>\n",
       "      <th>grants01</th>\n",
       "      <th>auxiliary01</th>\n",
       "      <th>totaloper01</th>\n",
       "      <th>other01</th>\n",
       "      <th>eandg01</th>\n",
       "      <th>rschpub01</th>\n",
       "      <th>acadinststud01</th>\n",
       "      <th>appliedaid01</th>\n",
       "      <th>grant07</th>\n",
       "      <th>tuition_discount</th>\n",
       "      <th>any_aid_num</th>\n",
       "      <th>loan_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21271000.0</td>\n",
       "      <td>6247000.0</td>\n",
       "      <td>10678000.0</td>\n",
       "      <td>7620000.0</td>\n",
       "      <td>25400000.0</td>\n",
       "      <td>11559000.0</td>\n",
       "      <td>17830000.0</td>\n",
       "      <td>5524000.0</td>\n",
       "      <td>7262000.0</td>\n",
       "      <td>145062000.0</td>\n",
       "      <td>19198000.0</td>\n",
       "      <td>101190000.0</td>\n",
       "      <td>19138000.0</td>\n",
       "      <td>43698000.0</td>\n",
       "      <td>10719000.0</td>\n",
       "      <td>20669000.0</td>\n",
       "      <td>0.694820</td>\n",
       "      <td>768.0</td>\n",
       "      <td>410.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3381000.0</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>586000.0</td>\n",
       "      <td>759000.0</td>\n",
       "      <td>1438000.0</td>\n",
       "      <td>287000.0</td>\n",
       "      <td>233000.0</td>\n",
       "      <td>444000.0</td>\n",
       "      <td>656000.0</td>\n",
       "      <td>7874000.0</td>\n",
       "      <td>853000.0</td>\n",
       "      <td>6985000.0</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>2783000.0</td>\n",
       "      <td>389000.0</td>\n",
       "      <td>849000.0</td>\n",
       "      <td>0.078713</td>\n",
       "      <td>69.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7759162.0</td>\n",
       "      <td>533007.0</td>\n",
       "      <td>216781.0</td>\n",
       "      <td>877732.0</td>\n",
       "      <td>2433057.0</td>\n",
       "      <td>1609337.0</td>\n",
       "      <td>479162.0</td>\n",
       "      <td>2373606.0</td>\n",
       "      <td>1404632.0</td>\n",
       "      <td>17686476.0</td>\n",
       "      <td>1293557.0</td>\n",
       "      <td>15802682.0</td>\n",
       "      <td>533007.0</td>\n",
       "      <td>3527570.0</td>\n",
       "      <td>1128995.0</td>\n",
       "      <td>3587855.0</td>\n",
       "      <td>0.040513</td>\n",
       "      <td>243.0</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8866137.0</td>\n",
       "      <td>499516.0</td>\n",
       "      <td>290757.0</td>\n",
       "      <td>1406955.0</td>\n",
       "      <td>2573069.0</td>\n",
       "      <td>948427.0</td>\n",
       "      <td>622235.0</td>\n",
       "      <td>2436324.0</td>\n",
       "      <td>1499302.0</td>\n",
       "      <td>19142722.0</td>\n",
       "      <td>763423.0</td>\n",
       "      <td>17021184.0</td>\n",
       "      <td>499516.0</td>\n",
       "      <td>4270781.0</td>\n",
       "      <td>1152778.0</td>\n",
       "      <td>3692224.0</td>\n",
       "      <td>0.049800</td>\n",
       "      <td>237.0</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9457812.0</td>\n",
       "      <td>469808.0</td>\n",
       "      <td>239381.0</td>\n",
       "      <td>1388520.0</td>\n",
       "      <td>2528163.0</td>\n",
       "      <td>1027562.0</td>\n",
       "      <td>1026184.0</td>\n",
       "      <td>3038049.0</td>\n",
       "      <td>1372520.0</td>\n",
       "      <td>20548000.0</td>\n",
       "      <td>877750.0</td>\n",
       "      <td>18149296.0</td>\n",
       "      <td>469808.0</td>\n",
       "      <td>4156064.0</td>\n",
       "      <td>1240168.0</td>\n",
       "      <td>4360728.0</td>\n",
       "      <td>0.046230</td>\n",
       "      <td>246.0</td>\n",
       "      <td>113.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instruction01  pubserv01  acadsupp01  studserv01  instsupp01  opermain01  \\\n",
       "0     21271000.0  6247000.0  10678000.0   7620000.0  25400000.0  11559000.0   \n",
       "1      3381000.0    90000.0    586000.0    759000.0   1438000.0    287000.0   \n",
       "2      7759162.0   533007.0    216781.0    877732.0   2433057.0   1609337.0   \n",
       "3      8866137.0   499516.0    290757.0   1406955.0   2573069.0    948427.0   \n",
       "4      9457812.0   469808.0    239381.0   1388520.0   2528163.0   1027562.0   \n",
       "\n",
       "   depreciation01   grants01  auxiliary01  totaloper01     other01  \\\n",
       "0      17830000.0  5524000.0    7262000.0  145062000.0  19198000.0   \n",
       "1        233000.0   444000.0     656000.0    7874000.0    853000.0   \n",
       "2        479162.0  2373606.0    1404632.0   17686476.0   1293557.0   \n",
       "3        622235.0  2436324.0    1499302.0   19142722.0    763423.0   \n",
       "4       1026184.0  3038049.0    1372520.0   20548000.0    877750.0   \n",
       "\n",
       "       eandg01   rschpub01  acadinststud01  appliedaid01     grant07  \\\n",
       "0  101190000.0  19138000.0      43698000.0    10719000.0  20669000.0   \n",
       "1    6985000.0     90000.0       2783000.0      389000.0    849000.0   \n",
       "2   15802682.0    533007.0       3527570.0     1128995.0   3587855.0   \n",
       "3   17021184.0    499516.0       4270781.0     1152778.0   3692224.0   \n",
       "4   18149296.0    469808.0       4156064.0     1240168.0   4360728.0   \n",
       "\n",
       "   tuition_discount  any_aid_num  loan_num  \n",
       "0          0.694820        768.0     410.0  \n",
       "1          0.078713         69.0      16.0  \n",
       "2          0.040513        243.0     102.0  \n",
       "3          0.049800        237.0     110.0  \n",
       "4          0.046230        246.0     113.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4609, 19)  Features dataset structure\n",
      "(4609L,)  Label dataset structure\n"
     ]
    }
   ],
   "source": [
    "# target or label\n",
    "y = data['totalcompletions']\n",
    "# features\n",
    "x = data.drop(['totalcompletions','has_completions'], axis=1)\n",
    "display(x.head())\n",
    "print x.shape, ' Features dataset structure' \n",
    "print y.shape, ' Label dataset structure' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier Detection\n",
    "Detecting outliers in the data is extremely important in the data preprocessing step of any analysis. The presence of outliers can often skew results which take into consideration these data points. There are many \"rules of thumb\" for what constitutes an outlier in a dataset. Here, Tukey's Method is used for identifying outliers: An outlier step is calculated as 1.5 times the interquartile range (IQR). A data point with a feature that is beyond an outlier step outside of the IQR for that feature is considered abnormal. Once this implementation has performed, 67 entries are detected as outliers and removed from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outliers: 251\n"
     ]
    }
   ],
   "source": [
    "outliers  = []\n",
    "# For each feature find the data points with extreme high or low values\n",
    "for feature in x.keys():\n",
    "    \n",
    "    # Calculate Q1 (25th percentile of the data) for the given feature\n",
    "    Q1 = np.percentile(x[feature], 25)\n",
    "    \n",
    "    # Calculate Q3 (75th percentile of the data) for the given feature\n",
    "    Q3 = np.percentile(x[feature], 75)\n",
    "    \n",
    "    # Use the interquartile range to calculate an outlier step (1.5 times the interquartile range)\n",
    "    step = 1.5*(Q3-Q1)\n",
    "    \n",
    "    # Display the outliers\n",
    "#    print \"Data points considered outliers for the feature '{}':\".format(feature)\n",
    "    outlier = (x[~((x[feature] >= Q1 - step) & (x[feature] <= Q3 + step))])\n",
    "#    display(outlier)\n",
    "\n",
    "# OPTIONAL: Select the indices for data points you wish to remove\n",
    "    for i in outlier.index: \n",
    "        outliers.append(i)\n",
    "        \n",
    "# Remove the outliers, if any were specified\n",
    "good_data = x.drop(x.index[outliers]).reset_index(drop = True)\n",
    "print 'Number of outliers:', len(outlier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Visualization\n",
    "To get a better understanding of the dataset, both heatmap and scatter matrix of all the features are constructed and illustrated in next figures. \n",
    "\n",
    "There are high correlations between most of the variables. For instance, **instruction01** feature correlates with most of the variables specially with **eandg01, totaloper0** and **opermain01** features. Few features like **tuition_discount** and **other01** have no significant correlation with other features. As the plot shows, expenditure feature sets are highly correlated with almost all of financial aid features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAu0AAALwCAYAAAAj9ksiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nINwDBy7xPUAkYH0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x3811e898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.tools.plotting import table\n",
    "\n",
    "#Visualize the correlation for each feature pair\n",
    "plt.figure(figsize=(8,8))\n",
    "corr = x.corr()\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "cmap= sns.cubehelix_palette(start=-0.4, rot=0.1, dark=.2, light=.95,as_cmap=True)\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=1, square=True, linewidths=.2,)\n",
    "plt.title('Correlations between features ', size=20)\n",
    "plt.tight_layout()\n",
    "#plt.savefig(\"01.png\", dpi=600);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Distributions\n",
    "Scatter matrix is able to demonstrate whether the feature we attempted to predict are relevant to each other or not. It also, revels if the distribution is normal or skewed. Considering figure below, the relatively large standard deviations indicate the distributions are spread out. In addition, it shows the distributions are highly skewed for almost all the features. The feature rescaling and data transformation could help us to change our data distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# scatter matrix first half of features \n",
    "sm = pd.scatter_matrix(x[x.keys()[:]], alpha = 0.3, figsize = (20,15), diagonal = 'kde');\n",
    "for subaxis in sm:\n",
    "    for ax in subaxis:\n",
    "        ax.xaxis.set_ticks([])\n",
    "        ax.yaxis.set_ticks([])\n",
    "        #ax.set_ylabel(\"\")\n",
    "        #ax.set_xlabel(\"\")\n",
    "#pic = sm[0][0].get_figure()  \n",
    "#pic.savefig(\"02.png\", dpi=300)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming Skewed Continuous Features\n",
    "If data is not normally distributed, especially if the mean and median vary significantly (indicating a large skew), it is most often appropriate to apply a non-linear scaling, particularly for financial data. One way to achieve this scaling is by using a Box-Cox test, which calculates the best power transformation of the data that reduces skewness. A simpler approach which can work in most cases would be applying the natural logarithm where it will be implemented in this section.\n",
    "\n",
    "Figure below shows the log-transformed data, the scatter matrix of first five features after applying a natural logarithm scaling to the data. The distribution of each feature appears much more normal. For any pairs of features that have been identified earlier as being correlated, the correlation is still present and it is now stronger and more clear than before.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Replacing zero values with one to avoid infinity logaritmic values\n",
    "x[x==0] = 1\n",
    "\n",
    "# Scale the data using the natural logarithm\n",
    "x_log = np.log(x)\n",
    "y_log = np.log(y)\n",
    "\n",
    "# Produce a scatter matrix for each pair of newly-transformed features\n",
    "sm = pd.scatter_matrix(x_log[x_log.keys()[:]], alpha = 0.3, figsize = (20,15), diagonal = 'kde');\n",
    "for subaxis in sm:\n",
    "    for ax in subaxis:\n",
    "        ax.xaxis.set_ticks([])\n",
    "        ax.yaxis.set_ticks([])\n",
    "        #ax.set_ylabel(\"\")\n",
    "        #ax.set_xlabel(\"\")\n",
    "#pic = sm[0][0].get_figure()  \n",
    "#pic.savefig(\"03.png\", dpi=300)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithms and Techniques\n",
    "So far, the datasets have been loaded with *python pandas* library and stored as a data frame. After removing outliers, missing values, unnecessary data points and features, the log transformation of data was implemented. Next, cross-validation function will be used to split the data into training and the testing datasets (75% assigned to training datasets and 25% assigned to testing datasets).\n",
    "\n",
    "Having the training and testing datasets ready, the Principal Component Analysis (PCA) will be implemented to find the dimensions that explain the most of the variance. The top components become predicting features for creating next models. Before the PCA procedure, the standardizing and feature scaling procedures will be performed on the dataset.\n",
    "\n",
    "Different algorithms will be used to create predictive models. These models will be able to predict a specific institution completion rate based on its expenditure and financial aid features. The following are few supervised learning models that are currently available in scikit-learn that from which four algorithms will be selected and studied further in this project.\n",
    "\n",
    "* **K-Nearest Neighbor Regressor:** The model estimates value by the closest data points, and the model costs less with minimal tuning.\n",
    "* **Decision Tree Regressor:** The model is easy to implement and also performs very fast. Once trained the model predicts very quick. The model gives a clear structure of how it makes a prediction, but the downside is the prediction may lack interpretation.\n",
    "* **Support Vector Regressor:** The model is also a commonly used model. SVR has solid founding theory, less prone to over-fitting, and need less tuning.\n",
    "* **Multiple Layer Perceptron Regressor:** The model uses the structure of a neural network and is regaining popularity due to numerous applications on voice and image recognition.\n",
    "* **Random Forest Regressor:** The model creates multiple decision trees and trains with data through bootstrap sampling. Every node on the branch will randomly choose a small amount of the features. The trees will be tested with data not sampled. This method can avoid over-fitting to training data by its randomness. The setting has ten decision trees as estimators with no maximum depth and considers all the features when looking for the best split. No maximum for the leaf node and the minimum samples leaf is one.\n",
    "\n",
    "In the next step, the models will be optimized and tuned using Grid Search function and sets of hyperparameters. The metrics mentioned before will be imported from scikit-learn package and will be used to evaluate different models and their testing results. \n",
    "\n",
    "The final goal would be finding the most accurate model which is capable of predicting target label (completion rates) with highest performance scores. An important task when performing supervised learning on a dataset like this is determining which features provide the most predictive power. By focusing on the relationship between only a few crucial features and the target label, one could simplify the understanding of the phenomenon, which is almost always a useful thing to do. Moreover, using the Principal Component Analysis, a list of expenditure and financial aid features will be selected to be used as inputs for the final model in order to speed up the prediction process while maintaining the accuracy in an acceptable range.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark model\n",
    "An un-tuned *AdaBoostRegressor* is used as the Benchmark Model. This model is trained and tested on the original training and testing datasets (datasets before implementing the log-transformation). Next, the selected models will be trained using PCA-transformed datasets and will be tuned and optimized further. The evaluation metrics and performance scores (R<sup>2</sup>) will be used to compare the results of the benchmark model against other models and the optimized ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "#Divide label and data and randomly choose training and testing set\n",
    "xi_train, xi_test, yi_train, yi_test=cross_validation.train_test_split(x, y, test_size=0.25, random_state=42)\n",
    "\n",
    "#Calcuate benchmark with untuned DecisionTreeRegressor()\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor, GradientBoostingRegressor\n",
    "\n",
    "\n",
    "benchmark = AdaBoostRegressor(random_state = 0)\n",
    "benchmark = benchmark.fit(xi_train,yi_train);\n",
    "\n",
    "predictions = benchmark.predict(xi_test)\n",
    "R2score = performance_metric(yi_test, predictions) \n",
    "\n",
    "print \"R2 score on the testing data:        {:.4f}\".format(performance_metric(yi_test, predictions))\n",
    "print \"Regressor.score on the testing data: {:.4f}\".format(benchmark.score(xi_test, yi_test))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "In addition to data cleaning procedures and performing log-transformation on features that are highly skewed, it is often good practice to perform some type of feature scaling on numerical features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling\n",
    "Applying a scaling to the data does not change the shape of each feature's distribution, however, normalization ensures that each feature is treated equally when applying supervised learners. Moreover, once scaling is applied, observing the data in its raw form will no longer have the same original meaning. sklearn *MinMaxScaler* is used to normalize each numerical feature.\n",
    "\n",
    "Typically, learning algorithms expect input to be numeric, which requires that non-numeric features (called categorical variables) be converted into a \"dummy\" variables. Since there are no features that are non-numeric, the encoding step will be skipped.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import sklearn.preprocessing.StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Initialize a scaler, then apply it to the features\n",
    "scaler = MinMaxScaler() # default=(0, 1)\n",
    "\n",
    "#features_log_minmax_transform = pd.DataFrame(data = features_log_transformed)\n",
    "x_log_transform= pd.DataFrame(scaler.fit_transform(x_log), columns=x_log.keys())\n",
    "y_log_transform= pd.DataFrame(scaler.fit_transform(y_log),  columns=['totalcompletions'])['totalcompletions']\n",
    "\n",
    "# Show an example of a record with scaling applied\n",
    "display(x_log_transform.head(n = 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA\n",
    "In this section, Principal Component Analysis (PCA) is used to draw conclusions about the underlying structure of the Expenditure/Financial datasets. Since using PCA on a dataset calculates the dimensions which best maximize variance, it shows which compound combinations of features best describe the target label.\n",
    "\n",
    "Now that the data has been scaled to a more normal distribution and has had any necessary outliers removed, PCA is applied to the dataset to discover which dimensions about the data best maximize the variance of features involved. In addition to finding these dimensions, PCA will also report the explained variance ratio of each dimension, i.e. how much variance within the data is explained by that dimension alone. Note that a component (dimension) from PCA can be considered a new \"feature\" of the space however, it is a composition of the original features present in the data. Figure below shows the normalized explained variance ratio (weights) both incrementally and cumulatively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Apply PCA by fitting the good data with the same number of dimensions as features\n",
    "x_train, x_test, y_train, y_test = cross_validation.train_test_split(x_log_transform, y, test_size=0.25, random_state=42)\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(x_train)\n",
    "x_pca_train = pca.transform(x_train)\n",
    "x_pca_train = pd.DataFrame(x_pca_train, index=x_train.index)\n",
    "\n",
    "x_pca_test = pca.transform(x_test)\n",
    "x_pca_test = pd.DataFrame(x_pca_test, index=x_test.index)\n",
    "\n",
    "print 'pca.explained_variance_\\n\\n', pca.explained_variance_, '\\n\\n'\n",
    "print 'explained_variance_ratio_\\n\\n', pca.explained_variance_ratio_, '\\n\\n'\n",
    "\n",
    "importances = pca.explained_variance_ratio_\n",
    "fig = vs.feature_plot(importances, x_pca_train, y_train)\n",
    "#fig.savefig(\"04.png\", dpi=300,bbox_inches='tight');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction\n",
    "Based on Figure above, 81% of the variance in the data is explained in total by the first and second principal component and 10% by third and fourth principal components. Therefore, we can say 91% of the variance in the data is explained by the first four dimensions. \n",
    "\n",
    "When using principal component analysis, one of the main goals is to reduce the dimensionality of the data, in effect, reducing the complexity of the problem. Dimensionality reduction comes at a cost: Fewer dimensions used implies less of the total variance in the data is being explained. Because of this, the cumulative explained variance ratio is extremely important for knowing how many dimensions are necessary for the problem. Additionally, if a significant amount of variance is explained by only two or three dimensions, the reduced data can be visualized afterward.\n",
    "\n",
    "In this study, we chose to reduce the dimensionality to seven principal components since 97% of the variance in the data is explained in total by the first seven components. Figure below shows the results of assigning and fitting PCA in seven dimensions with the final dataset.\n",
    "\n",
    "Note that a positive increase in a specific dimension corresponds with an increase of the positive-weighted features and a decrease of the negative-weighted features. The rate of increase or decrease is based on the individual feature weights.\n",
    "\n",
    "Using the visualization below, one can see the first dimension best represent all the expenditure and financial aid categories. The second dimension is totally in a different direction and mostly depends on **loan_num** feature.\n",
    "\n",
    "The third dimension differentiates between the effect of **pubser01** and **rschpub01** versus the rest of features and the fourth dimension further accentuate the difference between **other01** versus **pubser01** and **rschpub01**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#####################################################################\n",
    "from sklearn.decomposition import PCA\n",
    "# Apply PCA by fitting the good data with the same number of dimensions as features\n",
    "pca = PCA(n_components = 7)\n",
    "pca.fit(x_train)\n",
    "x_reduced_train = pca.transform(x_train)\n",
    "x_reduced_train = pd.DataFrame(x_reduced_train, index=x_train.index)\n",
    "\n",
    "x_reduced_test = pca.transform(x_test)\n",
    "x_reduced_test = pd.DataFrame(x_reduced_test, index=x_test.index)\n",
    "\n",
    "# Generate PCA results plot\n",
    "results = vs.pca_results(x_train, pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import visuals as vs\n",
    "# Apply PCA by fitting the good data with only two dimensions\n",
    "pca_feature = PCA(n_components=2)\n",
    "x_train_feature = x_train.loc[:,('loan_num','pubserv01','rschpub01','other01','grants01','tuition_discount')]\n",
    "pca_feature.fit(x_train_feature)\n",
    "\n",
    "# Transform the good data using the PCA fit above\n",
    "reduced_data = pca_feature.transform(x_train_feature)\n",
    "reduced_data = pd.DataFrame(reduced_data, index=x_train.index)\n",
    "\n",
    "# Create a biplot\n",
    "vs.biplot(x_train_feature, reduced_data, pca_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "From the mentioned list of the supervised learning models, four algorithms that are more appropriate for regression analysis of this project have been selected and will be tested on the IPDES dataset. These algorithms are; *DecisionTreeRegressor, KNeighborsRegressor, AdaBoostRegressor*, and *RandomForestRegressor*. These algorithms can handle lots of irrelevant features and perform well with large datasets. Other models aren't suitable for high-dimensional cases and are prone to overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Training and Predicting Pipeline\n",
    "To properly evaluate the performance of each selected model, it's important to create a training and predicting pipeline that allows us to quickly and effectively train models using various sizes of training data and perform predictions on the testing data. The implementation here will be used in the following section. \n",
    "\n",
    "In the predicting pipeline, at first, the score metrics are imported from *sklearn*. Then the learner will be *fit* to the sampled training data and the training time will be recorded. Next, predictions on the testing dataset and also on the first 300 training data points will be performed and the total prediction time will be recorded. Finally, R<sup>2</sup> score for both the training subset and testing set will be calculated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_predict(learner, sample_size, X_pca_train, X_reduced_train, y_train, X_reduced_test, X_pca_test, y_test): \n",
    "    '''\n",
    "    inputs:\n",
    "       - learner: the learning algorithm to be trained and predicted on\n",
    "       - sample_size: the size of samples (number) to be drawn from training set\n",
    "       - X_train: features training set\n",
    "       - y_train: income training set\n",
    "       - X_test: features testing set\n",
    "       - y_test: income testing set\n",
    "    '''\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Fit the learner to the training data using slicing with 'sample_size' using .fit(training_features[:], training_labels[:])\n",
    "    start = time() # Get start time\n",
    "    learner_pca = learner.fit(X_pca_train[:sample_size], y_train[:sample_size])\n",
    "    end = time() # Get end time\n",
    "\n",
    "    # Calculate the training time\n",
    "    results['train_time'] = end - start\n",
    "        \n",
    "    # Get the predictions on the test set(X_test),\n",
    "    #       then get predictions on the first 300 training samples(X_train) using .predict()\n",
    "    start = time() # Get start time\n",
    "    predictions_pca_test = learner_pca.predict(X_pca_test)\n",
    "    predictions_pca_train = learner_pca.predict(X_pca_train[:300])\n",
    "    end = time() # Get end time\n",
    "    \n",
    "    learner_reduced = learner.fit(X_reduced_train[:sample_size], y_train[:sample_size])\n",
    "    predictions_reduced_test = learner_reduced.predict(X_reduced_test)\n",
    "    predictions_reduced_train = learner_reduced.predict(X_reduced_train[:300])\n",
    "    \n",
    "    # Calculate the total prediction time\n",
    "    results['pred_time'] = end - start\n",
    "    \n",
    "    # Compute accuracy on the first 300 training samples which is y_train[:300]\n",
    "    results['R2_pca_train'] = performance_metric(y_train[:300], predictions_pca_train)\n",
    "        \n",
    "    # Compute accuracy on test set using accuracy_score()\n",
    "    results['R2_pca_test'] = performance_metric(y_test, predictions_pca_test)\n",
    "    \n",
    "    # Compute F-score on the the first 300 training samples using fbeta_score()\n",
    "    beta = 0.5\n",
    "    results['R2_reduced_train'] = performance_metric(y_train[:300], predictions_reduced_train)    \n",
    "    # Compute F-score on the test set which is y_test\n",
    "    results['R2_reduced_test'] = performance_metric(y_test, predictions_reduced_test)   \n",
    "    # Success\n",
    "    print \"{} trained on {} samples.\".format(learner.__class__.__name__, sample_size)\n",
    "        \n",
    "    # Return the results\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Model Evaluation\n",
    "Four supervised learning models discussed in the previous section are imported from *sklearn* and initialized and stored in *Reg_A, Reg_B, Reg_C*, and *Reg_D*. A random_state and the default settings for each model is used. (tuning and optimization will be done on specific models in next sections).  Samples of training data (equal to 1%, 10%, and 100% of the training data) are used for training each model. Finally, the models are tested using the testing dataset and the results are collected in the figure below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Import the three supervised learning models from sklearn\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression, Perceptron\n",
    "from sklearn.ensemble import AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from time import time\n",
    "\n",
    "\n",
    "# Initialize the four models\n",
    "clf_A = DecisionTreeRegressor()\n",
    "#clf_C = MLPRegressor()\n",
    "clf_B = KNeighborsRegressor()\n",
    "#clf_C = GradientBoostingRegressor()\n",
    "#clf_C = SVR()\n",
    "clf_C = AdaBoostRegressor()\n",
    "clf_D = RandomForestRegressor()\n",
    "\n",
    "# Calculate the number of samples for 1%, 10%, and 100% of the training data\n",
    "samples_100 = int(x_reduced_train.shape[0]*1)\n",
    "samples_10 = int(x_reduced_train.shape[0]*0.1)\n",
    "samples_1 = int(x_reduced_train.shape[0]*0.01)\n",
    "\n",
    "# Collect results on the learners\n",
    "results = {}\n",
    "for clf in [clf_A, clf_B, clf_C, clf_D]:\n",
    "    clf_name = clf.__class__.__name__\n",
    "    results[clf_name] = {}\n",
    "    for i, samples in enumerate([samples_1, samples_10, samples_100]):\n",
    "        results[clf_name][i] = \\\n",
    "        train_predict(clf, samples, x_pca_train, x_reduced_train, y_train, x_reduced_test, x_pca_test, y_test)\n",
    "\n",
    "# Run metrics visualization for the three supervised learning models chosen\n",
    "fig = vs.evaluate(results, R2score, R2score)\n",
    "#fig.savefig(\"06.png\", dpi=600,bbox_inches='tight');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'R2 score on PCA_reduced testing subset with 100% sample:\\n'\n",
    "for k in results.keys():\n",
    "    print k,':  ', results[k][2]['R2_reduced_test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing the Best Model\n",
    "\n",
    "Based on our evaluation, *RandomForestRegressor* model seems to be the most appropriate one for the task of predicting institutes completion rates using Expenditure/Financial data features. *KNeighborsRegressor* model has the highest R2 score on both PCA and reduced PCA testing sets when 100% of the training set is used (0.96 and 0.95 respectively). *RandomForestRegressor* has almost the same R<sup>2</sup> score results (0.95 and 0.94 respectively) but it has a significantly shorter testing time. On the other hand, *KNeighborsRegressor* has shorter training time which makes it very competitive with *RandomForestRegressor* and the second choice in terms of efficiency. Moreover, *DecisionTreeRegressor* has lowest performance results although it has the fastest training and testing time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refinement\n",
    "## Model Tuning using Grid Search and Cross-Validation\n",
    "In this section, the chosen models (*RandomForestRegressor* and *KNeighborsRegressor*) are optimized and fine-tuned. *k-fold* cross validation split the training set into k bins, use a bean as testing data and use rest of the data as training data and validate against testing data. It repeats the process k times. The performance measure reported by *k-fold* cross validation is then the average of the values computed in the loop. *k-fold* cross validation especially useful for small dataset since it maximizes both test and training data.\n",
    "\n",
    "This technique is very useful for grid search when optimizing a model. The grid search, systematically working through multiple combinations of Hyper-parameters, tunes and determine which one gives the best performance.\n",
    "\n",
    "In this project, grid search function (*GridSearchCV*) is used with a couple of important parameters (hyperparameters) tuned with at least 3 different values. A dictionary of parameters is created to tune for the chosen model and the entire training set are being used for this process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import 'make_scorer', 'DecisionTreeRegressor', and 'GridSearchCV'\n",
    "from sklearn.metrics import make_scorer \n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "def fit_model(X, y, model, params):\n",
    "    \"\"\" Performs grid search over the 'max_depth' parameter for a \n",
    "        decision tree regressor trained on the input data [X, y]. \"\"\"\n",
    "    \n",
    "    # Create cross-validation sets from the training data\n",
    "    # sklearn versiin 0.17: ShuffleSplit(n, n_iter=10, test_size=0.1, train_size=None, random_state=None)\n",
    "    #cv_sets = ShuffleSplit(X.shape[0], n_iter = 10, test_size = 0.20, random_state = 0)\n",
    "\n",
    "    # Create a regressor object\n",
    "    regressor = model\n",
    "\n",
    "    # Create a dictionary for the parameter 'max_depth' with a range from 1 to 10\n",
    "    params = params\n",
    "\n",
    "    # Transform 'performance_metric' into a scoring function using 'make_scorer' \n",
    "    #scoring_fnc = adj_r2_score(model,X,y)\n",
    "    scoring_fnc = make_scorer(performance_metric)\n",
    "    \n",
    "    # Create the grid search cv object --> GridSearchCV()\n",
    "    # (estimator, param_grid, scoring, cv) which have values 'regressor', 'params', 'scoring_fnc', and 'cv_sets' respectively.\n",
    "    grid = GridSearchCV(regressor, param_grid = params, scoring = scoring_fnc)\n",
    "\n",
    "    # Fit the grid search object to the data to compute the optimal model\n",
    "    grid_fit = grid.fit(X, y)\n",
    "    best_clf = grid_fit.best_estimator_\n",
    "    \n",
    "    # Make predictions using the unoptimized and optimized models\n",
    "    predictions = (clf.fit(x_reduced_train, y_train)).predict(x_reduced_test)\n",
    "    best_predictions = best_clf.predict(x_reduced_test)\n",
    "    print \"unoptimized model score on the testing data: {:.4f}\".format(performance_metric(y_test, predictions))\n",
    "    print \"optimized model score on the testing data:   {:.4f}\".format(performance_metric(y_test, best_predictions))\n",
    "    # metric_score_cv(X, y, best_clf,10)\n",
    "    return grid_fit.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation and Validation\n",
    "The table below shows the optimized model's R<sup>2</sup> score on the PCA reduced testing data along with the results from our unoptimized model and the benchmarks model discussed earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = KNeighborsRegressor()\n",
    "params={'n_neighbors':[1,3,5,10,20,50,70,100], \n",
    "        'weights':['uniform','distance'],\n",
    "        'algorithm':['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "        'leaf_size':[1,5,10,30,50]\n",
    "       }\n",
    "model_opt = fit_model(x_reduced_train, y_train, model, params)\n",
    "display (model_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = RandomForestRegressor()\n",
    "\n",
    "params = {'n_estimators':[10,50,100,200,500],\n",
    "          'max_features':['auto', 'sqrt', 'log2'],\n",
    "          'max_depth':[10, 20, 30, 50],\n",
    "          'min_samples_split':[2, 4, 8],\n",
    "          'bootstrap':[True, False]\n",
    "         }\n",
    "model_opt = fit_model(x_reduced_train, y_train, model, params)\n",
    "display (model_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train on the \"best\" model found from grid search earlier\n",
    "clf_o = (clone(model_opt)).fit(xi_train, yi_train)\n",
    "predictions_o = clf_o.predict(xi_test)\n",
    "print \"unoptimized model score on the testing data: {:.4f}\".format(performance_metric(yi_test, predictions_o))\n",
    "\n",
    "#xi_train, xi_test, yi_train, yi_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "|                       | Benchmark Predictor | Unoptimized Model | Optimized Model |\n",
    "| :-------------------: | :-----------------: | :---------------: | :-------------: | \n",
    "| RandomForestRegressor |       0.8413        |      0.9494       |     0.9552      |\n",
    "| KNeighborsRegressor   |       0.8413        |      0.9561       |     0.9636      |\n",
    "\n",
    "The above table shows optimized model's score on the testing data are 0.9552 and 0.9636 respectively which are slightly better than the unoptimized model. The hyperparameters tuning using grid search (GridSearchCV) were effective for our models. Our optimized models performed significantly better than the benchmark model. The R<sup>2</sup> score changed from 0.8413 to 0.9552 and 0.9636."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The first objective of this project was to find out whether the completion rates could be predicted based on financial aid and expenditure data from post-secondary education institutions and which predictive model can handle this task with the highest performance score.\n",
    "\n",
    "Implementing PCA procedure, the 19 features that we selected and processed from original IPEDS dataset, were reduced to 7 dimensions. Using this transformed data, different models were tested on the testing dataset and *RandomForestRegressor* showed the best performance among all candidates in terms of testing time and R<sup>2</sup> score. As a result, this model is selected as the best model in terms of predicting target labels (institutes completion rates).\n",
    "\n",
    "The following section includes the detail of optimized and tuned hyperparameters for the first choice model, *RandomForestRegressor* and second choice model, *KNeighborsRegressor*.\n",
    "\n",
    "* **KNeighborsRegressor**(algorithm='auto', leaf_size=1, metric='minkowski',metric_params=None, n_jobs=1, n_neighbors=3, p=2, weights='distance')\n",
    "\n",
    "* **RandomForestRegressor**(bootstrap=False, criterion='mse', max_depth=50, max_features='log2', max_leaf_nodes=None, min_impurity_split=1e-07, min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1, oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
    "\n",
    "As the second objective of this project, an important task when performing supervised learning on a dataset like the education dataset under study here is determining which features provide the most predictive power. By focusing on the relationship between only a few crucial features and the target label we simplify our understanding of the phenomenon, which is almost always a useful thing to do. In the case of this project, that means we wish to identify a few number of features that most strongly predict institutes completion rates.\n",
    "\n",
    "Using PCA analysis performed before and based on Reduced PCA figure, 97% of the variance in the data is explained in total by the first seven principal component. The significant positive increase in a specific dimension corresponds with an increase of the positive-weighted features and a decrease of the negative-weighted features. The rate of increase or decrease is based on the individual feature weights. Using the visualization, one can see the first dimension best represent all the expenditure and financial aid categories. The second dimension is totally in a different direction and mostly depends on **loan_num** feature. The third dimension differentiates between the effect of **pubser01** and **rschpub01** versus the rest of features and the fourth dimension further accentuate the difference between **other01** versus **pubser01** and **rschpub01**. These features are most strongly predicting the institutes completion rates. **pubser01** is the expense category that provides noninstructional services beneficial to individuals and groups external to the institution such as conferences. **loan_num** is the number of full-time, first-time degree/certificate-seeking undergraduate students who received student loans. Other features can be looked up in the Feature section table.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection\n",
    "This project focused on studying and analyzing different components of the expenditure and financial aid of higher education institutes and utilized them to predict the total number of awards, certificates, and degrees completed each year in these institutions. The project successfully used different tools such as PCA to find the effective combination of features and tested and optimized different algorithms to come up with a model capable of performing better than the benchmark model and other candidates.\n",
    "\n",
    "Data cleaning and selecting proper features for analysis were the most time-consuming part of this project. For example, some institution runs private labs and hospitals while others have collaboration with industrial or tech companies and finding a common ground to make feature selection was complicated. Many fields excluded for being not relevant to this study and lots of data points with missing values were deleted eventually. Finding suitable algorithms for regression analysis was also struggling. While some well-known ensemble methods (such as Random Forest) seems to be a good fit but their characteristics and specific behavior of these models might not be the best option when dealing with IPEDS dataset. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improvement\n",
    "The project has lots of room for improvement. Rather than predicting the rankings of institutes using financial and expenditure data, one can include or exclusively use other features such as revenue, number of faculties and employees, geographic region, census division, Carnegie classification, and years to graduation. Moreover, other categories of expenditure and financial aid that has not been included in this study can be considered. \n",
    "\n",
    "In addition, different data cleaning approaches or data transformation methods could be examined further. PCA reduces problem dimensionality into a specific number of principal components. With further investigation, one might be able to run multiple scenarios with different combinations of components and see its effect on model performances. Using other algorithms such as *Gradient Boosting Regressor* or *Support Vector Regressor* for regression analysis along with more effective grid search procedure could be studied further as well.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "1.\tIntegrated Postsecondary Education Data System Delta Cost Project Database, https://nces.ed.gov/ipeds/deltacostproject/\n",
    "2.\tRankings of universities in the United States, https://en.wikipedia.org/wiki/Rankings_of_universities_in_the_United_States\n",
    "3.\t2009–2010 College Rankings: National Universities, http://www.parchment.com/\n",
    "4.\tStatistics and Probability Dictionary, http://stattrek.com/statistics/dictionary.aspx?definition=coefficient_of_determination\n",
    "5.\t\"Applied to Stanford or Harvard? You probably didn’t get in. Admit rates drop, again.\". Retrieved 13 May 2016. https://www.washingtonpost.com/news/grade-point/wp/2016/04/01/\n",
    "6.\tDrucker, H. (1997, July). Improving regressors using boosting techniques. In ICML (Vol. 97, pp. 107-115).\n",
    "7.\tGuyon, I., & Elisseeff, A. (2003). An introduction to variable and feature selection. Journal of machine learning, research, 3(Mar), 1157-1182.\n",
    "8.\tNational Conference of State Legislatures (2015, July 31). Performance-based Funding for Higher Education Retrieved from http://www.ncsl.org/research/education/performance-funding.aspx\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:DAND]",
   "language": "python",
   "name": "conda-env-DAND-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
